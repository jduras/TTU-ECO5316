---
title: "Gao_eco5316_HW5"
author: "Shijia Gao"
date: "3/11/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r}
# install.packages("tibbletime")    
# install.packages("uroot")
# install.packages ("tseries")
# install.packages("urca")

library(tidyquant)
library(timetk)
library(tibbletime)
library(broom)
library(sweep)
library(ggplot2)
library(scales)
library(ggfortify)
library(egg)
library(tsibble)
library(tictoc)
library(forecast)
library(tseries)
library(uroot)
library(urca)


# set default theme for ggplot2
theme_set(theme_bw())
```


(a) Obtain monthly data for Total Nonfarm Payroll Employment, Not Seasonally Adjusted, available on FRED under code [`PAYNSA`]https://fred.stlouisfed.org/series/PAYNSA(). Import the 1975M1-2018M12 sample using `tq_get`.
 &
(b) Construct the following transformed time series
1. change in Total Nonfarm Payroll Employment $\Delta E_t = E_t - E_{t-1}$
2. log of Total Nonfarm Payroll Employment $\log E_t$
3. log change in Total Nonfarm Payroll Employment $\Delta \log E_t = \log E_t - \log E_{t-1}$
4. 12 month log change  in Total Nonfarm Payroll Employment $\Delta_{12} \log E_t = \log E_t - \log E_{t-12}$
5. twice differenced Total Nonfarm Payroll Employment $\Delta \Delta_{12} \log E_t = \Delta_{12} \log E_t - \Delta_{12} \log E_{t-1}$. 
```{r}
data.tbl <-
  tq_get("PAYNSA", get = "economic.data", from = "1975-01-01", to = "2018-12-01")  %>%
  rename(E = price) %>%
  ts(start = c(1975,1), frequency = 12) %>%
  tk_tbl() %>%
  mutate(lE = log(E),
         dE = E - lag(E),
         dlE1 = lE - lag(lE),
         dlE12 = lE - lag(lE, 12),
         d2lE12_1 = dlE12 - lag(dlE12))


#Plot the original and the transformed time series. Comment on their trends, volatility, seasonal patterns.
fstm <- 1975.00 
lstm <- 2019-(1/12)
data_tbl_1 <- data.tbl %>%
  filter(index <= as.yearmon(lstm))

data_tbl_1%>%
  gather(variable, value, -index,-date) %>%
  mutate(variable_label = factor(variable, ordered = TRUE,
                                 levels = c("E", "lE", "dE", "dlE1", "dlE12", "d2lE12_1"),
                                 labels = c("E", "log(E)",
                                            expression(paste(Delta,"E")),
                                            expression(paste(Delta,"log(E)")),
                                            expression(paste(Delta[12],"log(E)")),
                                            expression(paste(Delta,Delta[12],"log(E)"))))) %>%  
  ggplot(aes(x = index, y = value)) +
  geom_hline(aes(yintercept = 0), linetype = "dotted") +
  geom_line() +
  scale_x_yearmon() +
  labs(x = "", y = "") +
  facet_wrap(~variable_label, ncol = 3, scales = "free", labeller = label_parsed) +
  theme(strip.text = element_text(hjust = 0),
        strip.background = element_blank())   
```
Comments: From the above graphs, we can see the original monthly data for Total Nonfarm Payroll Employment is nonstationary, it shows some seasonal pattern and increasing trend, so we have to transform the data using a logarithm and apply both regular and seasonal differencing, namely d2lE12_1 = dlE12 - lag(dlE12), from the graph of d2LE12_1, we can see the data is roughly stationary around the mean of 0, which means the increasing trend is also removed. 


(c) Use `ggseasonplot` to create seasonal plots for $\Delta E_t$ and $\Delta \log E_t$. Comment on the seasonal patterns.
```{r}
data_tbl_1%>% tk_ts(select=dE, start=c(1975 ,1),frequency=12)%>% ggseasonplot
data_tbl_1%>% tk_ts(select=dlE1, start=c(1975,1),frequency=12)%>% ggseasonplot
```  
Comments: From the follwing graph, both $\Delta E_t$ and $\Delta \log E_t$ had shown seasonality pattern almost every 12months . 


(d) Plot ACF and PACF for $\log E_t, \Delta \log E_t, \Delta_{12} \log E_t, \Delta \Delta_{12} \log E_t$. Comment on their shape.
```{r}
maxlag <-24
g1 <- data_tbl_1  %>% pull(lE) %>% ggAcf(lag.max = maxlag, ylab = "", main = expression(paste("ACF for log(E)")))
g2 <- data_tbl_1  %>% pull(dlE1) %>% ggAcf(lag.max = maxlag, ylab = "", main = expression(paste("ACF for ", Delta,"log(E)")))
g3 <- data_tbl_1  %>% pull(dlE12) %>% ggAcf(lag.max = maxlag, ylab = "", main = expression(paste("ACF for ", Delta[12], "log(E)")))
g4 <- data_tbl_1  %>% pull(d2lE12_1) %>% ggAcf(lag.max = maxlag, ylab = "", main = expression(paste("ACF for ", Delta, Delta[12], "log(E)")))
g5 <- data_tbl_1  %>% pull(lE) %>% ggPacf(lag.max = maxlag, ylab = "", main = expression(paste("PACF for log(E)")))
g6 <- data_tbl_1  %>% pull(dlE1) %>% ggPacf(lag.max = maxlag, ylab = "", main = expression(paste("PACF for ", Delta, "log(E)")))
g7 <- data_tbl_1  %>% pull(dlE12) %>% ggPacf(lag.max = maxlag, ylab = "", main = expression(paste("PACF for ", Delta[12], "log(E)")))
g8 <- data_tbl_1 %>% pull(d2lE12_1) %>% ggPacf(lag.max = maxlag, ylab = "", main = expression(paste("PACF for ", Delta,Delta[12], "log(E)")))

ggarrange(g1, g2, g3, g4, g5, g6, g7, g8, ncol = 4)

```
Comments: For log E_t, it shows a gradual decline in the ACF and a spike which almost equals to 1 at first lag in the PACF, so there is a unit root. 
      For Delta \log E_t, the first large spike in the ACF of log E_t has gone now, which is good, but there are some spikes at lag6, lag 12, lag18, lag24, and in the PACF, spikes are at lag6, lag 12, so there must be some seasonal pattern, and it's more like multiplicative seasonal MA model. 
      For Delta_{12} \log E_t, it's like AR(3) model.
      For Delta \Delta_{12} \log E_t, There is a gradual decline every 12 lags in ACF, and in PACF, there are some large spikes in lag 1, lag2, lag3 and lag12, and small spikes in lag 13, lag 14 and lag 24, so we can estimate that the model is AR(3) with seasonal pattern, the frequency is 12, namely the model might be ARIMA(3,0,0)(3,0,0)[12], and we can estimate it later. 


(e) Perform the ADF and KPSS tests on $\log E_t, \Delta_{12} \log E_t, \Delta \Delta_{12} \log E_t$. Summarize the results.
```{r}
data.ts1 <- data.tbl %>%
  tk_ts(select = lE, start = fstm, frequency = 12)
ur.df(data.ts1,type="drift", selectlags="AIC")%>%summary()
ur.kpss(data.ts1,type="mu", lags="long")%>%summary()

data.ts2 <- na.omit(data.tbl) %>%
  tk_ts(select = dlE12, start = fstm, frequency = 12)
  ur.df(data.ts2,type="drift", selectlags="AIC")%>%summary()
  ur.kpss(data.ts2,type="mu", lags="long")%>%summary()
  
data.ts3 <- na.omit(data.tbl) %>%
  tk_ts(select = d2lE12_1, start = fstm, frequency = 12)
  ur.df(data.ts3,type="drift", selectlags="AIC")%>%summary()
  ur.kpss(data.ts3,type="mu", lags="long")%>%summary()
```
Comments: FOr log E_t, since tau3 in the DF tests is  -1.8841 which is larger than the critical value at 1%, 5%, and 10%, so we fail to reject the null hypothesis and conclude that there is a unit root. In KPSS test, since the value of test-statistic is  2.7416, which is greater than the critical values at 1%, 2.5%, 5%, and 10%, so we reject the null hypothesis and conclude that there is no mean stationarity.                                                                    
        FOr Delta_{12} \log E_t, since tau3 in the DF tests is -2.6022 which is larger than the critical value at 1%, 5%, so we fail to reject the null hypothesis and conclude that there is a unit root. In KPSS test, since the value of test-statistic is 0.4387, which is smaller than the critical values at 1%, 2.5%, 5%, so we fail to reject the null hypothesis and conclude that there is mean stationarity.                                                                       
        FOr Delta \Delta_{12} \log E_t$, since tau3 in the DF tests is -8.4245 which is smaller than the critical value at 1%, 5%, and 10%, so we reject the null hypothesis and conclude that there is no unit root. In KPSS test, since the value of test-statistic is 0.0241, which is smaller than the critical values at 1%, 2.5%, 5%, and 10%, so we fail to reject the null hypothesis and conclude that there is mean stationarity.                                                                  
        Therefore, by taking two differences of log E_t, the data now is mean stationary and with no unit root, which is good. 


(f) Split the sample into two parts: estimation sample from 1975M1 to 2014M12, and prediction sample from 2015M1 to 2018M12. Use ACF and PACF from (c) to identify and estimate a suitable model for $\Delta \Delta_{12} \log E_t$ using `Arima`. Check the estimated model for adequacy - diagnose residuals using `ggtsdiag`
```{r}
# split sample - estimation and prediction subsamples
fstm1 <- 1975.000 
lstm1 <- 2015-(1/12)
fstm2 <- 2015.000 
lstm2 <- 2019-(1/12)

##Use ACF and PACF from (d), we can identify and estimate a suitable model is ARIMA(3,0,0)(3,0,0)[12]
me<- data_tbl_1 %>%
  tk_ts(select = d2lE12_1, start = fstm1, frequency = 12) %>% 
  Arima(order = c(3,0,0), seasonal = list(order = c(3,0,0), period = 12))
  ggtsdiag(me, gof.lag = maxlag)
```
Comments: From the graph, we can get the estimated model ARIMA(3,0,0)(3,0,0)[12] perform well in both estimation sample and prediction sample, no seasonal pattern is present in the ACF of residuals, standardized residuals are white noise, and p values are quite large. 

(g) Use `auto.arima` to find the best model for $\log E_t$. Check the estimated model for adequacy - diagnose residuals using `ggtsdiag`. 
```{r}
m1<- data_tbl_1 %>%
      tk_ts(select = lE, start = fstm1, frequency = 12) %>%
      auto.arima(ic = "aic", seasonal = TRUE,stationary = FALSE, stepwise = FALSE, approximation =  FALSE)
m1
ggtsdiag(m1,gof.lag=36)
```
Comments: From auto.arima, we can get the model is ARIMA(3,1,0)(1,1,1)[12]. the result is very well. no seasonal pattern is present in the ACF of residuals, standardized residuals are white noise and p values are large.


(h) Use `slide` from `tsibble` package to create a rolling scheme sequence of 1 period ahead forecasts for the prediction subsample 2015M1-2018M12 using the same model specification as in (g).
```{r}
      fstm1 <- 1975 
      lstm1 <- 2015-(1/12)
      
      window.length <- data.tbl%>%
        filter(index <= as.yearmon(lstm1)) %>%
        nrow()
      
      tic()
      results <-
        data.tbl %>%
        mutate(yearm= yearmonth(index)) %>%
        as_tsibble(index = yearm) %>%                                        # covert to tsibble
        mutate(sarima.model = slide(lE, ~auto.arima(.x, ic = "aicc", seasonal = TRUE, approximation = FALSE, stepwise = TRUE),
                                    .size = window.length)) %>%             # estimate models
        filter(!is.na(sarima.model)) %>%                                    
        mutate(sarima.coefs = map(sarima.model, tidy, conf.int = TRUE),
               sarima.fcst = map(sarima.model, (. %>% forecast(1) %>% sw_sweep())))
      toc()
      results
```


(i) Plot the forecast for $E_t$ from (h) together with its confidence intervals and the actual data for the period 2008M1-2018M12.
```{r}
#Forecasts
 fstm1 <- 1975 
 lstm1 <- 2015-(1/12)
data.ts_4<- data.tbl%>%
  filter(index <= as.yearmon(lstm1)) %>%
  tk_ts(select = E, start=fstm1, frequency = 12)   

# actual data  
actual_tbl <-
  data.tbl %>%
  select(index, E) %>%
  mutate(key = "actual",
         date = as.Date(index)) %>%
  select(date, key, E) %>% filter(year(date) >= 2008)
actual_tbl

# estimate rolling SARIMA model, create 1 step ahead forecasts
PE_tbl_f_1 <-   results %>%
  select(yearm, sarima.fcst) %>%
  as_tibble() %>%
  unnest(sarima.fcst) %>%
  filter(key == "forecast") %>%
  mutate(yearm = yearm %m+% months(1) %>% yearmonth()) %>%
  mutate_at(vars(value, lo.80, lo.95, hi.80, hi.95), list(exp)) %>%
  rename(E = value) %>%
  select(yearm, key, E, lo.80, lo.95, hi.80, hi.95)

# forecast & actual data in a single tibble    
f_a_tbl <- bind_rows(actual_tbl ,
                     PE_tbl_f_1 %>%
                       mutate(date= as.Date(yearm)) %>%
                       select(date, key, E, lo.80, lo.95, hi.80, hi.95), .id = NULL)
f_a_tbl

# plot 1-month ahead rolling forecasts - levels
gf1<-f_a_tbl %>%
    filter(date >= "1975-01-01") %>%
    ggplot(aes(x =date, y = E, col = key, linetype = key)) +
         geom_ribbon(aes(ymin = lo.95, ymax = hi.95), linetype = "blank", fill = "blue", alpha = 0.1) +
         geom_ribbon(aes(ymin = lo.80, ymax = hi.80), linetype = "blank", fill = "blue", alpha = 0.2) +
         geom_line() +
         geom_point() +
        scale_color_manual(values = c("gray40","blue")) +
        scale_linetype_manual(values = c("solid","solid")) +
        labs(x = "", y = "",
        title = "Total Nonfarm Payroll Employment: 1-Step Ahead Rolling Forecast") +
         theme(legend.position = "none") 
gf1
```
Comments: # from the result, it seems that this forecast performs well. The trend and seasonal pattern of the forecasts are close to the characteristics of the actual data.  


(j) Use the forecast for $E_t$ from (h) to construct the forecast for $\Delta E_t$, plot it together with the actual data.
```{r}
data.ts_5<- data.tbl%>%
  filter(index <= as.yearmon(lstm1)) %>%
  tk_ts(select = dE, start=fstm1, frequency = 12)  

# actual data  
actual_tbl_2 <-
  data.tbl %>%
  select(index, dE) %>%
  mutate(key = "actual",
         date = as.Date(index)) %>%
  select(date, key, dE) %>% filter(year(date) >= 2008)
actual_tbl_2

# estimate rolling SARIMA model, create 1 step ahead forecasts
PE_tbl_f_2 <-results %>%
  select(yearm, sarima.fcst) %>%
  as_tibble() %>%
  unnest(sarima.fcst) %>%
  filter(key == "forecast") %>%
  mutate(yearm = yearm %m+% months(1) %>% yearmonth()) %>%
  mutate_at(vars(value, lo.80, lo.95, hi.80, hi.95), list(exp)) %>%
  mutate(dE = value-lag(value)) %>%
  select(yearm, key, dE, lo.80, lo.95, hi.80, hi.95)

# forecast & actual data in a single tibble    ##combine the forecasts and actual data, then we can plot them together
f_a_tbl_2 <- bind_rows(actual_tbl_2,
                       PE_tbl_f_2 %>%
                       mutate(date= as.Date(yearm)) %>%
                       select(date, key, dE, lo.80, lo.95, hi.80, hi.95), .id = NULL)
f_a_tbl_2 


# plot 1-month ahead rolling forecasts - levels
gf2<-f_a_tbl_2 %>%
  filter(date >= "2013-01-01") %>%
  ggplot(aes(x = date, y = dE, col = key, linetype = key)) +
  # geom_ribbon(aes(ymin = lo.95, ymax = hi.95), linetype = "blank", fill = "blue", alpha = 0.1) +
  # geom_ribbon(aes(ymin = lo.80, ymax = hi.80), linetype = "blank", fill = "blue", alpha = 0.2) +
  geom_line() +
  geom_point() +
  scale_color_manual(values = c("gray40","blue")) +
  scale_linetype_manual(values = c("solid","solid")) +
  labs(x = "", y = "",
       title = "First difference of Nonfarm Payroll Employment: 1-Step Ahead Rolling Forecast") 
  #theme(legend.position = "none")   
gf2
```
Comments: from the result, this forecast doesn't perform well, it deviates from the actual data in a larger extent and it's not consisent with the seasonality pattern of the actual data. 

(k) Construct and plot the forecast errors for $E_t$ and for $\Delta E_t$.
```{r}
#the forecast errors for $E_t$
f_a_tbl %>% 
  select(date, key, E)%>%
  spread(key,E)%>%
  mutate(error=actual-forecast,
         percen_error=(actual-forecast)/actual*100) %>%
  tk_ts(select=percen_error, start=2008,frequency = 12)%>%
  autoplot()

#the forecast errors for $\Delta E_t$
f_a_tbl_2 %>% 
  select(date, key, dE)%>%
  spread(key,dE)%>%
  mutate(error=actual-forecast) %>%
  filter(date >="2015-01-01") %>%
  tk_ts(select=error, start=2008,frequency = 12)%>%
  autoplot()    # note: it doesn't make sense to calculate percentage error here. 
```
Comments: From the graphs we can get the forecast percentage error term for $E_t$ vibrates from -1.5% to 1%, but 1.5% is actually 1.5 million people, and since the unit for the data is "thousands of person", so the error term is quite large. For the forecast  error term for $Delta E_t$, we can see the range of the error term is still quite large and we also get some problems of seasonal pattern. Therefore both forecasts need improvements. 